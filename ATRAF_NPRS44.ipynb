{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMD4N9bjXgAbBQx6hcDlXUT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"VRoxcbu_BBE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692437239465,"user_tz":-120,"elapsed":18854,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}},"outputId":"cf1602ee-c377-497e-f580-1cddabecb975"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/PhDResearch/ATRAF'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-kykokNBDWE","executionInfo":{"status":"ok","timestamp":1692437242990,"user_tz":-120,"elapsed":350,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}},"outputId":"1478681c-9b8b-44cb-8a7f-d0abdc8ba6e3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PhDResearch/ATRAF\n"]}]},{"cell_type":"markdown","source":["## Training Transformer"],"metadata":{"id":"WAp-TZK34Y7O"}},{"cell_type":"markdown","source":[],"metadata":{"id":"lJolBWJnZMY8"}},{"cell_type":"code","source":["import copy\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.nn.modules.normalization import LayerNorm\n","\n","# Autoencoder\n","class Encoder(nn.Module):\n","    def __init__(self, in_seq_len, out_seq_len, d_model, dropout=0.1):\n","        super().__init__()\n","        self.in_seq_len = in_seq_len\n","        self.out_seq_len = out_seq_len\n","        self.d_model = d_model\n","        self.input_dims = self.in_seq_len * self.d_model\n","        self.output_dims = self.out_seq_len * self.d_model\n","        self.dims_1 = (self.input_dims - self.output_dims) // 4 * 3\n","        self.dims_2 = (self.input_dims - self.output_dims) // 4 * 2\n","\n","        linear1 = nn.Linear(self.input_dims, self.dims_1)\n","        linear2 = nn.Linear(self.dims_1, self.dims_2)\n","        linear3 = nn.Linear(self.dims_2, self.output_dims)\n","\n","        self.flatten = nn.Flatten()\n","        self.linears = nn.ModuleList([linear1, linear2, linear3])\n","        self.dropout = dropout\n","        self.unflatten = nn.Unflatten(1, (self.out_seq_len, self.d_model))\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        for i, l in enumerate(self.linears):\n","            x = F.relu(l(x))\n","            x = nn.Dropout(p=self.dropout)(x)\n","        x = self.unflatten(x)\n","        return x\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, in_seq_len, out_seq_len, d_model, dropout=0.1):\n","        super().__init__()\n","        self.in_seq_len = in_seq_len\n","        self.out_seq_len = out_seq_len\n","        self.d_model = d_model\n","        self.input_dims = self.in_seq_len * self.d_model\n","        self.output_dims =  self.out_seq_len * self.d_model\n","        self.dims_1 = (self.input_dims - self.output_dims) // 4 * 3\n","        self.dims_2 = (self.input_dims - self.output_dims) // 4 * 2\n","\n","        linear1 = nn.Linear(self.output_dims, self.dims_2)\n","        linear2 = nn.Linear(self.dims_2, self.dims_1)\n","        linear3 = nn.Linear(self.dims_1, self.input_dims)\n","\n","        self.linears = nn.ModuleList([linear1, linear2, linear3])\n","        self.dropout = dropout\n","        self.flatten = nn.Flatten()\n","        self.unflatten = nn.Unflatten(1, (self.in_seq_len, self.d_model))\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        for i, l in enumerate(self.linears):\n","            x = F.relu(l(x))\n","            x = nn.Dropout(p=self.dropout)(x)\n","        x = self.unflatten(x)\n","        return x\n","\n","\n","class Autoencoder(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input):\n","        output = self.decoder(self.encoder(input))\n","        return output\n","\n","def make_autoencoder_model(in_seq_len, out_seq_len, d_model, dropout=0.1):\n","    encoder = Encoder(in_seq_len, out_seq_len, d_model, dropout)\n","    decoder = Decoder(in_seq_len, out_seq_len, d_model, dropout)\n","    model = Autoencoder(encoder, decoder)\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","    return model\n","\n","\n"],"metadata":{"id":"oq9N8S6pS17l","executionInfo":{"status":"ok","timestamp":1692437251336,"user_tz":-120,"elapsed":5069,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\"\"\" This code is a slightly modified version of The Annotated Transformer.\"\"\"\n","\n","class TransformerModel(nn.Module):\n","    def __init__(self, encoder, src_embed, linear):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.src_embed = src_embed\n","        self.linear = linear\n","\n","    def forward(self, src, src_mask):\n","        output = F.relu(self.linear(\n","            self.encoder(self.src_embed(src), src_mask)))\n","        return output\n","\n","\n","def clones(module, N):\n","    \"\"\"\n","    Produce N identical layers\n","    \"\"\"\n","    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n","\n","\n","class TransformerEncoder(nn.Module):\n","    \"Core encoder is a stack of N layers\"\n","\n","    def __init__(self, layer, N):\n","        super().__init__()\n","        self.layers = clones(layer, N)\n","        self.norm = LayerNorm(layer.size)\n","\n","    def forward(self, x, mask):\n","        \"Pass the input (and mask) through each layer in turn\"\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","        return self.norm(x)\n","\n","\n","class SublayerConnection(nn.Module):\n","    \"\"\"\n","    A residual connection followed by a layer norm.\n","    Note for code simplicity the norm is first as opposed to last.\n","    \"\"\"\n","\n","    def __init__(self, size, dropout):\n","        super().__init__()\n","        self.norm = LayerNorm(size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, sublayer):\n","        \"\"\"\n","        Apply residual connection to any sublayer with the same size.\n","        \"\"\"\n","        return x + self.dropout(sublayer(self.norm(x)))\n","\n","\n","class TransformerEncoderLayer(nn.Module):\n","    \"\"\"\n","    Encoder is made up of self-attn and feed foward\n","    \"\"\"\n","\n","    def __init__(self, size, self_attn, feed_forward, dropout):\n","        super().__init__()\n","        self.self_attn = self_attn\n","        self.feed_forward = feed_forward\n","        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n","        self.size = size\n","\n","    def forward(self, x, mask):\n","        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n","        return self.sublayer[1](x, self.feed_forward)\n","\n","\n","def attention(query, key, value, mask=None, dropout=0.0):\n","    \"\"\"Compute the Scaled Dot-Product Attention\"\"\"\n","    d_k = query.size(-1)\n","    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, -1e9)\n","    p_attn = F.softmax(scores, dim=-1)\n","    p_attn = F.dropout(p_attn, p=dropout)\n","    return torch.matmul(p_attn, value), p_attn\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, h, d_model, dropout=0.1):\n","        \"\"\"\n","        Take in model size and number of heads.\n","        \"\"\"\n","        super().__init__()\n","        assert d_model % h == 0\n","        self.d_k = d_model // h\n","        self.h = h\n","        self.p = dropout\n","        self.linears = clones(nn.Linear(d_model, d_model), 4)\n","        self.attn = None\n","\n","    def forward(self, query, key, value, mask=None):\n","        if mask is not None:\n","            # Same mask applied to all h heads.\n","            mask = mask.unsqueeze(1)\n","        nbatches = query.size(0)\n","        # 1) Do all the linear projections in batch from d_model => h x d_k\n","        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n","                             for l, x in zip(self.linears, (query, key, value))]\n","        # 2) Apply attention on all the projected vectors in batch\n","        x, self.attn = attention(query, key, value, mask=mask, dropout=self.p)\n","        # 3) \"Concat\" using a view and apply a final linear\n","        x = x.transpose(1, 2).contiguous().view(\n","            nbatches, -1, self.h * self.d_k)\n","        return self.linears[-1](x)\n","\n","\n","class PositionwiseFeedForward(nn.Module):\n","    \"Implements FFN equation.\"\n","\n","    def __init__(self, d_model, d_ff, dropout=0.1):\n","        super().__init__()\n","        # Torch linears have a \"b\" by default.\n","        self.w_1 = nn.Linear(d_model, d_ff)\n","        self.w_2 = nn.Linear(d_ff, d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n","\n","\n","class PositionalEncoding(nn.Module):\n","    \"\"\" Implement the PE function. \"\"\"\n","\n","    def __init__(self, d_model, dropout, max_len=5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2)\n","                             * (-math.log(10000.0) / d_model))\n","\n","        pe[:, 0::2] = torch.sin(div_term * position)\n","        pe[:, 1::2] = torch.cos(div_term * position)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(self, x):\n","        x = x + Variable(self.pe[:, :x.size(1), :], requires_grad=False)\n","        return self.dropout(x)\n","\n","class FNetEncoderLayer(nn.Module):\n","    \"\"\"\n","    Encoder is made up of a Fourier Mixing Layer and a FF Layer\n","    \"\"\"\n","\n","    def __init__(self, size, fft, feed_forward, dropout):\n","        super().__init__()\n","        self.fft = fft\n","        self.feed_forward = feed_forward\n","        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n","        self.size = size\n","\n","    def forward(self, x):\n","        x = self.sublayer[0](x, lambda x: self.fft(x, x, x))\n","        return self.sublayer[1](x, self.feed_forward)\n","\n","\n","class FourierFFTLayer(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, query, key, value):\n","        assert query is key\n","        assert key is value\n","\n","        x = query\n","        return torch.real(torch.fft.fft(torch.fft.fft(x, dim=-1), dim=-2))\n","\n","\n","class FNetHybridModel(nn.Module):\n","    def __init__(self, trans, src_embed, linear, fnet):\n","        super().__init__()\n","        self.trans = trans\n","        self.src_embed = src_embed\n","        self.linear = linear\n","        self.fnet = fnet\n","\n","    def forward(self, src, src_mask):\n","        output = F.relu(self.linear(self.fnet(\n","            self.trans(self.src_embed(src), src_mask))))\n","        return output\n","\n","\n","class FNetEncoder(nn.Module):\n","    \"Core Fnet is a stack of N layers\"\n","\n","    def __init__(self, layer, N):\n","        super().__init__()\n","        self.layers = clones(layer, N)\n","        self.norm = LayerNorm(layer.size)\n","\n","    def forward(self, x):\n","        \"Pass the input through each layer in turn\"\n","        for layer in self.layers:\n","            x = layer(x)\n","        return self.norm(x)\n","\n","\n","\n","class FNetEncoderLayer(nn.Module):\n","    \"\"\"\n","    Encoder is made up of a Fourier Mixing Layer and a FF Layer\n","    \"\"\"\n","\n","    def __init__(self, size, fft, feed_forward, dropout):\n","        super().__init__()\n","        self.fft = fft\n","        self.feed_forward = feed_forward\n","        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n","        self.size = size\n","\n","    def forward(self, x):\n","        x = self.sublayer[0](x, lambda x: self.fft(x, x, x))\n","        return self.sublayer[1](x, self.feed_forward)\n","\n","\n","class FourierFFTLayer(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, query, key, value):\n","        assert query is key\n","        assert key is value\n","\n","        x = query\n","        return torch.real(torch.fft.fft(torch.fft.fft(x, dim=-1), dim=-2))\n","\n","def make_transformer_model(N, d_model, l_win, d_ff=0, h=8, dropout=0.1):\n","    if (d_ff == 0):\n","        d_ff = d_model * 4\n","    c = copy.deepcopy\n","    attn = MultiHeadAttention(h, d_model, dropout)\n","    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n","    position = PositionalEncoding(d_model, dropout, l_win)\n","    final_linear = nn.Linear(d_model, d_model)\n","    model = TransformerModel(\n","        TransformerEncoder(TransformerEncoderLayer(\n","            d_model, c(attn), c(ff), dropout), N),\n","        nn.Sequential(position),\n","        final_linear\n","    )\n","\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","    return model\n","\n","def create_fnet_hybrid(N, d_model, l_win, d_ff=0, h=8, dropout=0.1):\n","    if (d_ff == 0):\n","        d_ff = d_model * 4\n","    # if (d_ff == 0):\n","    # d_ff = d_model * 4\n","    c = copy.deepcopy\n","    attn = MultiHeadAttention(h, d_model, dropout)\n","    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n","    position = PositionalEncoding(d_model, dropout, l_win)\n","    final_linear = nn.Linear(d_model, d_model)\n","    fft = FourierFFTLayer()\n","    model = FNetHybridModel(\n","        TransformerEncoder(TransformerEncoderLayer(\n","            d_model, c(attn), c(ff), dropout), 1),\n","        nn.Sequential(position),\n","        final_linear,\n","        FNetEncoder(FNetEncoderLayer(d_model, c(fft), c(ff), dropout), N - 1)\n","    )\n","\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform_(p)\n","    return model\n","\n","\n","\n"],"metadata":{"id":"JaXnnJUP40pD","executionInfo":{"status":"ok","timestamp":1692437251338,"user_tz":-120,"elapsed":19,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import argparse\n","import json\n","import os\n","\n","\n","def get_config_from_json(json_file):\n","    \"\"\"\n","    Get the config from a json file\n","    :param: json_file\n","    :return: config(dictionary)\n","    \"\"\"\n","    # parse the configurations from the config json file provided\n","    with open(json_file, \"r\") as config_file:\n","        config_dict = json.load(config_file)\n","        config_file.close()\n","    return config_dict\n","\n","\n","def save_config(config):\n","    filename = config[\"result_dir\"] + config[\"auto_dataset\"] + \"/\" + \\\n","        \"training_config_l_win_{}_auto_dims_{}.json\".format(\n","            config[\"l_win\"], config[\"autoencoder_dims\"])\n","    with open(filename, 'w', encoding='utf-8') as f:\n","        json.dump(config, f, indent=4)\n","\n","def process_config(json_file):\n","    config = get_config_from_json(json_file)\n","\n","    # create directories to save experiment results and trained models\n","    if config[\"load_dir\"] == \"default\":\n","        save_dir = \"../experiments/{}/{}/{}\".format(\"Transformer\",\n","            config[\"experiment\"], config[\"auto_dataset\"])\n","    else:\n","        save_dir = config[\"load_dir\"]\n","    config[\"summary_dir\"] = os.path.join(save_dir, \"summary/\")\n","    config[\"result_dir\"] = os.path.join(save_dir, \"result/\")\n","    config[\"checkpoint_dir\"] = os.path.join(\n","        save_dir, \"checkpoints/\")\n","    return config\n","\n","\n","def create_dirs(*dirs):\n","    \"\"\"\n","    dirs - a list of directories to create if these directories are not found\n","    :param dirs:\n","    :return exit_code: 0:success -1:failed\n","    \"\"\"\n","    try:\n","        for dir_ in dirs:\n","            if not os.path.exists(dir_):\n","                os.makedirs(dir_)\n","        return 0\n","    except Exception as err:\n","        print(\"Creating directories error: {0}\".format(err))\n","        exit(-1)\n","\n","\n","def get_args():\n","    argparser = argparse.ArgumentParser(description=__doc__)\n","    argparser.add_argument(\n","        \"-c\", \"--config\",\n","        metavar=\"C\",\n","        default=\"None\",\n","        help=\"The Configuration file\")\n","    # argparser.add_argument(\n","    #     \"-n\", \"--num-client\",\n","    #     default=1,\n","    #     help=\"The number of clients participating in Federated Learning\")\n","    args = argparser.parse_args()\n","    return args\n"],"metadata":{"id":"gq3wRpIk43EH","executionInfo":{"status":"ok","timestamp":1692437251339,"user_tz":-120,"elapsed":19,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from torch.utils.data import Dataset\n","\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, config, train=True, model_type=\"autoencoder\"):\n","        super().__init__()\n","        self.config = config\n","        self.train = train\n","        self.model_type = model_type\n","        if model_type == \"autoencoder\":\n","            self.load_dataset(self.config[\"auto_dataset\"])\n","        else:\n","            self.load_dataset(self.config[\"trans_dataset\"])\n","\n","    def __len__(self):\n","        # return self.rolling_windows.shape\n","        return self.rolling_windows.shape[0]\n","\n","\n","    def __getitem__(self, index):\n","        if (self.train) or (self.model_type == \"autoencoder\"):\n","            inp = target = self.rolling_windows[index, :, :]\n","        else:\n","            inp = self.rolling_windows[index, :, :]\n","            target = self.rolling_windows[index,\n","                                          self.config[\"pre_mask\"]:self.config[\"post_mask\"], :]\n","        sample = {\"input\": inp, \"target\": target}\n","        return sample\n","\n","    def load_dataset(self, dataset):\n","        data_dir = self.config[\"data_dir\"]\n","        # data_dir = \"../data/{}/\".format(self.config[\"data_dir\"])\n","        self.data = np.load(data_dir + dataset + \".npz\")\n","\n","        # slice training set into rolling windows\n","        if self.model_type == \"autoencoder\":\n","            if self.train:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"training\"], self.config[\"autoencoder_dims\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n","            else:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"test\"], self.config[\"autoencoder_dims\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n","        else:\n","            if self.train:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"training\"], self.config[\"l_win\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n","            else:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"test\"], self.config[\"l_win\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n"],"metadata":{"id":"fkJhM7Ok5Alo","executionInfo":{"status":"ok","timestamp":1692437251339,"user_tz":-120,"elapsed":18,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","import torch\n","from torch.utils.data.dataloader import DataLoader\n","\n","\n","device = torch.device(\"cuda\")\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","def create_dataloader(dataset, config):\n","    return DataLoader(dataset,\n","                      batch_size=config[\"batch_size\"],\n","                      shuffle=bool(config[\"shuffle\"]),\n","                      num_workers=config[\"dataloader_num_workers\"])\n","\n","\n","def loss_backprop(criterion, out, targets):\n","    assert out.size(1) == targets.size(1)\n","    loss = criterion(out, targets)\n","    loss.backward()\n","    return loss\n","\n","\n","def create_mask(config):\n","    mask = torch.ones(1, config[\"l_win\"], config[\"l_win\"])\n","    mask[:, config[\"pre_mask\"]:config[\"post_mask\"], :] = 0\n","    mask[:, :, config[\"pre_mask\"]:config[\"post_mask\"]] = 0\n","    mask = mask.float().masked_fill(mask == 0, float(\n","        \"-inf\")).masked_fill(mask == 1, float(0))\n","    return mask\n","\n","\n","min_trans_loss = float(\"inf\")\n","best_trans_model = None\n","epoch_trans_loss = list()\n","\n","def trans_train_epoch(train_iter, model, autoencoder, criterion, mask, opt, epoch, config):\n","    global min_trans_loss, best_trans_model, epoch_trans_loss\n","    model.train()\n","    model.to(device)\n","    autoencoder.eval()\n","    encoder = autoencoder.encoder\n","    encoder.to(device)\n","    batch_loss = list()\n","    for i, batch in enumerate(train_iter):\n","        src = batch[\"input\"].float()\n","        # src.to('cuda')\n","        src = encoder(src.cuda())\n","        trg = batch[\"target\"].float()\n","        # trg.to('cuda')\n","        trg = encoder(trg.cuda())\n","        # trg.to(device)\n","        out = model(src.cuda(), src_mask=mask.cuda())\n","\n","        opt.zero_grad()\n","        out.is_cuda\n","        trg.is_cuda\n","        loss = loss_backprop(criterion, out, trg)\n","        opt.step()\n","        batch_loss.append(loss.item())\n","\n","    if len(batch_loss) > 0:\n","        epoch_trans_loss.append(sum(batch_loss)/len(batch_loss))\n","        print('TRANSFORMER. Epoch: {} \\tTotal Loss: {:.6f}'.format(epoch,\n","                                                                          epoch_trans_loss[-1]))\n","\n","    if epoch_trans_loss[-1] < min_trans_loss:\n","        torch.save(model.state_dict(),\n","                   config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\" + f\"best_trans_{epoch}.pth\")\n","        torch.save(opt.state_dict(),\n","                   config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\" + f\"optimizer_trans_{epoch}.pth\")\n","        min_trans_loss = epoch_trans_loss[-1]\n","        best_trans_model = f\"best_trans_{epoch}.pth\"\n","    if best_trans_model != None:\n","        return best_trans_model\n","\n","\n","min_auto_loss = float(\"inf\")\n","best_auto_model = None\n","epoch_auto_loss = list()\n","\n","def autoencoder_train_epoch(train_iter, model, criterion, opt, epoch, config):\n","    global min_auto_loss, best_auto_model, epoch_auto_loss\n","    model.train()\n","    model.to(device)\n","    batch_loss = list()\n","    for i, batch in enumerate(train_iter):\n","        src = batch[\"input\"].float()\n","        src.to(device)\n","        trg = batch[\"target\"].float()\n","        trg.to(device)\n","        out = model(src.cuda())\n","        # out = model(src)\n","        opt.zero_grad()\n","        loss = loss_backprop(criterion, out, trg.cuda())\n","        opt.step()\n","        batch_loss.append(loss.item())\n","\n","    if len(batch_loss) > 0:\n","        epoch_auto_loss.append(sum(batch_loss)/len(batch_loss))\n","        print('AUTOENCODER. Epoch: {} \\tTotal Loss: {:.6f}'.format(epoch, epoch_auto_loss[-1]))\n","\n","    if epoch_auto_loss[-1] < min_auto_loss:\n","        torch.save(model.state_dict(),\n","                   config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\" + f\"best_autoencoder_{epoch}.pth\")\n","        torch.save(opt.state_dict(),\n","                   config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\" + f\"optimizer_autoencoder_{epoch}.pth\")\n","        min_auto_loss = epoch_auto_loss[-1]\n","        best_auto_model = f\"best_autoencoder_{epoch}.pth\"\n","    if best_auto_model != None:\n","        return best_auto_model"],"metadata":{"id":"OEhQbELy4gKX","executionInfo":{"status":"ok","timestamp":1692437251339,"user_tz":-120,"elapsed":16,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["config = {\n","    \"experiment\": \"SpaceShuttle\",\n","    \"data_dir\": \"/content/drive/MyDrive/PhDResearch/ATRAF/Anomaly-Detection-with-Transformer-Encoder/dataset/\",\n","    \"auto_dataset\": \"nprs44\",\n","    \"trans_dataset\": \"nprs44\",\n","    \"num_stacks\": 1,\n","    \"d_model\": 1,\n","    \"d_ff\": 128,\n","    \"num_heads\": 1,\n","    \"dropout\": 0.1,\n","    \"autoencoder_dims\": 100,\n","    \"l_win\": 25,\n","    \"pre_mask\": 10,\n","    \"post_mask\": 15,\n","    \"batch_size\": 64,\n","    \"shuffle\": 1,\n","    \"dataloader_num_workers\": 2,\n","    \"auto_num_epoch\": 10,\n","    \"trans_num_epoch\": 10,\n","    \"load_dir\": \"default\",\n","    \"checkpoint_dir\": \"/content/drive/MyDrive/PhDResearch/ATRAF/Anomaly-Detection-with-Transformer-Encoder/experiments/\",\n","    \"result_dir\": \"/content/drive/MyDrive/PhDResearch/ATRAF/Anomaly-Detection-with-Transformer-Encoder/result/\",\n","}"],"metadata":{"id":"R10oeVA18BTn","executionInfo":{"status":"ok","timestamp":1692437251340,"user_tz":-120,"elapsed":16,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# import json\n","# import os\n","\n","# num_stacks=[6,5,4,3,2,1]\n","# lr=[0.01, 0.005, 0.003, 0.002, 0.001]\n","# data=[\"scada2\", \"scada1\"]\n","# d_ff = [128, 64, 32]\n","# #auto_dims = [(200, 100), (200, 50), (100, 50), (100, 25), (150, 50), (80, 40), (150, 100), (50, 25)]\n","# batch_size = [128, 64, 32]\n","# #auto_dims = [(120, 40), (100, 40)]\n","# auto_dims = [(120, 60), (140, 70), ( 160, 80),  (180, 90)]\n","\n","\n","# for d in data:\n","#     for num in num_stacks:\n","#         for l in lr:\n","#             for ff in d_ff:\n","#                 for auto in auto_dims:\n","#                     for b in batch_size:\n","#                         filename = \"{}_CEN_AUTO_{}stacks_{}dff_{}auto_{}trans_{}lr_{}batch\".format(d.upper(), num, ff, auto[0], auto[1], l, b).replace(\".\", \"_\")\n","#                         print(filename)\n","#                         config_path = os.path.join(\"./configs/to_be_run\", \"{}.json\".format(filename))\n","#                         configs = {\n","#                             \"experiment\": filename,\n","#                             \"data_dir\": \"{}\".format(d),\n","#                             \"auto_dataset\": \"{}\".format(d),\n","#                             \"trans_dataset\": \"new_scada1\",\n","#                             \"num_stacks\": num,\n","#                             \"d_model\": 16,\n","#                             \"d_ff\": ff,\n","#                             \"num_heads\": 1,\n","#                             \"dropout\": 0.1,\n","#                             \"autoencoder_dims\": auto[0],\n","#                             \"l_win\": auto[1],\n","#                             \"pre_mask\": int(auto[1] / 5 * 2),\n","#                             \"post_mask\": int(auto[1] / 5 * 3),\n","#                             \"batch_size\": b,\n","#                             \"shuffle\": 1,\n","#                             \"dataloader_num_workers\": 10,\n","#                             \"auto_num_epoch\": 10,\n","#                             \"trans_num_epoch\": 15,\n","#                             \"load_dir\": \"default\"\n","#                         }\n","#                         with open(config_path, 'w', encoding='utf-8') as f:\n","#                             json.dump(configs, f, indent=4)"],"metadata":{"id":"uezSr1WvhI_F","executionInfo":{"status":"ok","timestamp":1692437251341,"user_tz":-120,"elapsed":16,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["result_dir = config[\"result_dir\"] + config[\"auto_dataset\"] + \"/\"\n","checkpoint_dir = config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\"\n","\n","create_dirs(result_dir, checkpoint_dir)\n","# create_dirs(config[\"result_dir\"], config[\"checkpoint_dir\"])\n","\n","dataset = CustomDataset(config)\n","dataloader = create_dataloader(dataset, config)\n","\n","# Training the autoencoder\n","start = time.time()\n","autoencoder_model = make_autoencoder_model(in_seq_len=config[\"autoencoder_dims\"],\n","                                            out_seq_len=config[\"l_win\"],\n","                                            d_model=config[\"d_model\"])\n","autoencoder_model.float()\n","model_opt = torch.optim.Adam(autoencoder_model.parameters())\n","criterion = torch.nn.MSELoss()\n","for epoch in range(config[\"auto_num_epoch\"]):\n","    config[\"best_auto_model\"] = autoencoder_train_epoch(dataloader,\n","                                                        autoencoder_model,\n","                                                        criterion,\n","                                                        model_opt,\n","                                                        epoch,\n","                                                        config)\n","print(\"COMPLETED TRAINING THE AUTOENCODER\")\n","config[\"auto_train_time\"] = (time.time() - start) / 60\n","\n","# Training the transformer model\n","start = time.time()\n","mask = create_mask(config)\n","# trans_model = make_transformer_model(N=config[\"num_stacks\"],\n","#                                       d_model=config[\"d_model\"],\n","#                                       l_win=config[\"l_win\"],\n","#                                       d_ff=config[\"d_ff\"],\n","#                                       h=config[\"num_heads\"],\n","#                                       dropout=config[\"dropout\"])\n","\n","trans_model = create_fnet_hybrid(N=config[\"num_stacks\"],\n","                                  d_model=config[\"d_model\"],\n","                                  l_win=config[\"l_win\"],\n","                                  d_ff=config[\"d_ff\"],\n","                                  h=config[\"num_heads\"],\n","                                  dropout=config[\"dropout\"])\n","\n","trans_model.float()\n","model_opt = torch.optim.Adam(trans_model.parameters())\n","autoencoder_model.load_state_dict(\n","    torch.load(config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\" + config[\"best_auto_model\"]))\n","for epoch in range(config[\"trans_num_epoch\"]):\n","    config[\"best_trans_model\"] = trans_train_epoch(dataloader,\n","                                                    trans_model,\n","                                                    autoencoder_model,\n","                                                    criterion,\n","                                                    mask,\n","                                                    model_opt,\n","                                                    epoch,\n","                                                    config)\n","print(\"COMPLETED TRAINING THE TRANSFORMER\")\n","config[\"trans_train_time\"] = (time.time() - start) / 60\n","save_config(config)\n"],"metadata":{"id":"DUrKvNcr49NW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692437279209,"user_tz":-120,"elapsed":27883,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}},"outputId":"cc8c2332-6f09-4fd0-ffcd-4337b854a98e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["AUTOENCODER. Epoch: 0 \tTotal Loss: 0.781420\n","AUTOENCODER. Epoch: 1 \tTotal Loss: 0.587470\n","AUTOENCODER. Epoch: 2 \tTotal Loss: 0.504282\n","AUTOENCODER. Epoch: 3 \tTotal Loss: 0.460838\n","AUTOENCODER. Epoch: 4 \tTotal Loss: 0.446510\n","AUTOENCODER. Epoch: 5 \tTotal Loss: 0.412340\n","AUTOENCODER. Epoch: 6 \tTotal Loss: 0.418792\n","AUTOENCODER. Epoch: 7 \tTotal Loss: 0.405301\n","AUTOENCODER. Epoch: 8 \tTotal Loss: 0.393518\n","AUTOENCODER. Epoch: 9 \tTotal Loss: 0.384641\n","COMPLETED TRAINING THE AUTOENCODER\n","TRANSFORMER. Epoch: 0 \tTotal Loss: 1.000521\n","TRANSFORMER. Epoch: 1 \tTotal Loss: 0.953880\n","TRANSFORMER. Epoch: 2 \tTotal Loss: 0.969919\n","TRANSFORMER. Epoch: 3 \tTotal Loss: 1.010954\n","TRANSFORMER. Epoch: 4 \tTotal Loss: 0.996197\n","TRANSFORMER. Epoch: 5 \tTotal Loss: 0.970090\n","TRANSFORMER. Epoch: 6 \tTotal Loss: 0.972431\n","TRANSFORMER. Epoch: 7 \tTotal Loss: 0.994556\n","TRANSFORMER. Epoch: 8 \tTotal Loss: 0.963084\n","TRANSFORMER. Epoch: 9 \tTotal Loss: 1.008046\n","COMPLETED TRAINING THE TRANSFORMER\n"]}]},{"cell_type":"markdown","source":["# **Testing**"],"metadata":{"id":"R5Agw6-hMXlC"}},{"cell_type":"code","source":["import math\n","import time\n","import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from scipy.stats import norm\n","from sklearn import metrics\n","\n","def load_model(config):\n","    autoencoder_model = make_autoencoder_model(in_seq_len=config[\"autoencoder_dims\"],\n","                                               out_seq_len=config[\"l_win\"],\n","                                               d_model=config[\"d_model\"])\n","    autoencoder_model.load_state_dict(torch.load(\n","        config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\" +  config[\"best_auto_model\"]))\n","    autoencoder_model.float()\n","    autoencoder_model.eval()\n","\n","    # trans_model = make_transformer_model(N=config[\"num_stacks\"],\n","    #                                      d_model=config[\"d_model\"],\n","    #                                      l_win=config[\"l_win\"],\n","    #                                      d_ff=config[\"d_ff\"],\n","    #                                      h=config[\"num_heads\"],\n","    #                                      dropout=config[\"dropout\"])\n","\n","    trans_model = create_fnet_hybrid(N=config[\"num_stacks\"],\n","                                  d_model=config[\"d_model\"],\n","                                  l_win=config[\"l_win\"],\n","                                  d_ff=config[\"d_ff\"],\n","                                  h=config[\"num_heads\"],\n","                                  dropout=config[\"dropout\"])\n","\n","    trans_model.load_state_dict(torch.load(\n","        config[\"checkpoint_dir\"] + config[\"auto_dataset\"] + \"/\" + config[\"best_trans_model\"]))\n","    trans_model.float()\n","    trans_model.eval()\n","\n","    return autoencoder_model.encoder, trans_model\n","\n","\n","def create_labels(idx_anomaly_test, n_test, config):\n","    anomaly_index = []\n","    test_labels = np.zeros(n_test)\n","    for i in range(len(idx_anomaly_test)):\n","        idx_start = idx_anomaly_test[i] - (config[\"l_win\"] + 1)\n","        idx_end = idx_anomaly_test[i] + (config[\"l_win\"] + 1)\n","        if idx_start < 0:\n","            idx_start = 0\n","        if idx_end > n_test:\n","            idx_end = n_test\n","        anomaly_index.append(np.arange(idx_start, idx_end))\n","        test_labels[idx_start:idx_end] = 1\n","    return anomaly_index, test_labels\n","\n","\n","def return_anomaly_idx_by_threshold(test_anomaly_metric, threshold):\n","    # test_list = np.squeeze(np.ndarray.flatten(test_anomaly_metric))\n","    idx_error = np.squeeze(np.argwhere(test_anomaly_metric > threshold))\n","\n","    if len(idx_error.shape) == 0:\n","        idx_error = np.expand_dims(idx_error, 0)\n","\n","    return list(idx_error)\n","\n","\n","def augment_detected_idx(idx_detected_anomaly, anomaly_index):\n","    n_anomaly = len(anomaly_index)\n","    idx_detected_anomaly_extended = list(idx_detected_anomaly)\n","    for i in range(n_anomaly):\n","        # print(idx_detected_anomaly)\n","        for j in idx_detected_anomaly:\n","            if j in anomaly_index[i]:\n","                in_original_detection = set(idx_detected_anomaly_extended)\n","                currect_anomaly_win = set(anomaly_index[i])\n","                idx_detected_anomaly_extended = idx_detected_anomaly_extended + \\\n","                    list(currect_anomaly_win - in_original_detection)\n","                # print(j)\n","                break\n","    return list(np.sort(idx_detected_anomaly_extended))\n","\n","\n","def count_TP_FP_FN(idx_detected_anomaly, test_labels):\n","    n_TP = 0\n","    n_FP = 0\n","    #n_detection = len(idx_detected_anomaly)\n","    # for i in range(n_detection):\n","    for i in idx_detected_anomaly:\n","        # if test_labels[idx_detected_anomaly[i]] == 1:\n","        if test_labels[i] == 1:\n","            n_TP = n_TP + 1\n","        else:\n","            n_FP = n_FP + 1\n","\n","    idx_undetected = list(set(np.arange(len(test_labels))\n","                              ) - set(idx_detected_anomaly))\n","    n_FN = 0\n","    for i in idx_undetected:\n","        if test_labels[i] == 1:\n","            n_FN = n_FN + 1\n","    n_TN = len(test_labels) - n_TP - n_FP - n_FN\n","    return n_TP, n_FP, n_FN, n_TN\n","\n","\n","def compute_precision_and_recall(idx_detected_anomaly, test_labels):\n","    # compute true positive\n","    n_TP, n_FP, n_FN, n_TN = count_TP_FP_FN(idx_detected_anomaly, test_labels)\n","\n","    if n_TP + n_FP == 0:\n","        precision = 1\n","    else:\n","        precision = n_TP / (n_TP + n_FP)\n","    recall = n_TP / (n_TP + n_FN)\n","    if precision + recall == 0:\n","        F1 = 0\n","    else:\n","        F1 = 2 * (precision * recall)/(precision + recall)\n","    fpr = n_FP/(n_FP + n_TN)\n","\n","    return precision, recall, F1, fpr, n_TP, n_FP, n_FN\n","\n","\n","def KQp(data, q):\n","    data2 = np.sort(data)  # sap xep tang dan\n","    n = np.shape(data2)[0]  # kich thuoc\n","    p = 1-q  # q tu xet, dat bang smth 0.05 0.025 0.01\n","    h = math.sqrt((p*q)/(n+1))\n","    KQ = 0\n","    for i in range(1, n+1):\n","        a = ((i/n)-p)/h\n","        b = (((i-1)/n)-p)/h\n","        TP = (norm.cdf(a)-norm.cdf(b))*data2[i-1]  # normcdf thu trong matlab\n","        KQ = KQ+TP\n","    # KQp = KQ;\n","    return KQ\n","\n","\n","def plot_roc_curve(fpr_aug, recall_aug, config, n_threshold=20):\n","    tpr = np.insert(recall_aug, [0, n_threshold], [0, 1])\n","    fpr = np.insert(fpr_aug, [0, n_threshold], [0, 1])\n","    auc = metrics.auc(fpr, tpr)\n","    print(\"AUC =\", auc)\n","    lw = 2\n","    plt.plot(fpr, tpr, color=\"darkorange\", lw=lw,\n","             label=\"ROC curve (area = %0.4f)\" % auc)\n","    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")\n","    plt.title(\"Augmented Receiver operating characteristic of \" +\n","              config[\"auto_dataset\"])\n","    plt.legend(loc=\"lower right\")\n","    plt.savefig(config[\"result_dir\"] + config[\"auto_dataset\"] + \"/\" + \"augmentedroc.pdf\")\n","    return auc\n","\n","\n","def select_threshold(recon_loss, anomaly_index, test_labels, config, n_threshold=20):\n","    \"\"\"\n","    Select best threshold based on best F1-score\n","    \"\"\"\n","    precision_aug = np.zeros(n_threshold)\n","    recall_aug = np.zeros(n_threshold)\n","    F1_aug = np.zeros(n_threshold)\n","    fpr_aug = np.zeros(n_threshold)\n","    i = 0\n","    threshold_list = np.linspace(np.amin(recon_loss), np.amax(\n","        recon_loss), n_threshold, endpoint=False)\n","    threshold_list = np.flip(threshold_list)\n","\n","    for threshold in threshold_list:\n","        # print(threshold_list[i])\n","        idx_detection = return_anomaly_idx_by_threshold(recon_loss, threshold)\n","        # augment the detection using the ground truth labels\n","        # a method to discount the factor one anomaly appears in multiple consecutive windows\n","        # introduced in \"Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications\"\n","        idx_detection_augmented = augment_detected_idx(\n","            idx_detection, anomaly_index)\n","        precision_aug[i], recall_aug[i], F1_aug[i], fpr_aug[i], _, _, _ = compute_precision_and_recall(idx_detection_augmented,\n","                                                                                                       test_labels)\n","        i = i + 1\n","        # print(precision, recall, F1)\n","\n","    auc = plot_roc_curve(fpr_aug, recall_aug, config)\n","\n","    print(\"\\nAugmented detection:\")\n","    print(\"Best F1 score is {}\".format(np.amax(F1_aug)))\n","    idx_best_threshold = np.squeeze(np.argwhere(F1_aug == np.amax(F1_aug)))\n","    print(\"Best threshold is {}\".format(threshold_list[idx_best_threshold]))\n","    best_thres = np.min(threshold_list[idx_best_threshold])\n","    print(\"At this threshold, precision is {}, recall is {}\".format(precision_aug[idx_best_threshold],\n","                                                                    recall_aug[idx_best_threshold]))\n","    return best_thres, auc\n","\n","\n","def select_KQp_threshold(threshold, recon_loss):\n","    q_list = [0.99, 0.9, 0.1]\n","    temp = math.inf\n","    q_best = 0\n","    for q in q_list:\n","        temp_thres = KQp(recon_loss, q)\n","        # print(temp_thres,abs(temp_thres - threshold))\n","        if abs(temp_thres - threshold) < temp:\n","            temp = abs(temp_thres - threshold)\n","            q_best = q\n","            KQp_thres = temp_thres\n","    print(\"Closest KQp threshold is {} at q = {}\".format(KQp_thres, q_best))\n","    return KQp_thres, q_best\n"],"metadata":{"id":"JLj3DaeGEsyP","executionInfo":{"status":"ok","timestamp":1692437280443,"user_tz":-120,"elapsed":1244,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, config, train=True, model_type=\"autoencoder\"):\n","        super().__init__()\n","        self.config = config\n","        self.train = train\n","        self.model_type = model_type\n","        if model_type == \"autoencoder\":\n","            self.load_dataset(self.config[\"auto_dataset\"])\n","        else:\n","            self.load_dataset(self.config[\"trans_dataset\"])\n","\n","    def __len__(self):\n","        # return self.rolling_windows.shape\n","        return self.rolling_windows.shape[0]\n","\n","\n","    def __getitem__(self, index):\n","        if (self.train) or (self.model_type == \"autoencoder\"):\n","            inp = target = self.rolling_windows[index, :, :]\n","        else:\n","            inp = self.rolling_windows[index, :, :]\n","            target = self.rolling_windows[index,\n","                                          self.config[\"pre_mask\"]:self.config[\"post_mask\"], :]\n","        sample = {\"input\": inp, \"target\": target}\n","        return sample\n","\n","    def load_dataset(self, dataset):\n","        data_dir = self.config[\"data_dir\"]\n","        # data_dir = \"../data/{}/\".format(self.config[\"data_dir\"])\n","        self.data = np.load(data_dir + dataset + \".npz\")\n","\n","        # slice training set into rolling windows\n","        if self.model_type == \"autoencoder\":\n","            if self.train:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"training\"], self.config[\"autoencoder_dims\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n","            else:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"test\"], self.config[\"autoencoder_dims\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n","        else:\n","            if self.train:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"training\"], self.config[\"l_win\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n","            else:\n","                self.rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","                    self.data[\"test\"], self.config[\"l_win\"], axis=0, writeable=True\n","                ).transpose(0, 2, 1)\n"],"metadata":{"id":"griTm5u2MiUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = \"/content/drive/MyDrive/PhDResearch/ATRAF/Anomaly-Detection-with-Transformer-Encoder/dataset/nprs44.npz\"\n","data = np.load(data_dir)\n","test = data[\"test\"]\n","print(test.shape)\n","# rolling_windows = np.lib.stride_tricks.sliding_window_view(\n","#                     data[\"test\"], config[\"autoencoder_dims\"], axis=0, writeable=True\n","#                 ).transpose(0, 2, 1)\n","test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37OVPU95NI9Q","executionInfo":{"status":"ok","timestamp":1692439509302,"user_tz":-120,"elapsed":21,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}},"outputId":"74566004-e651-4cb8-e7b6-f47e0eed9de3"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(0, 1)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([], shape=(0, 1), dtype=float64)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["print(data.files)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jsa7fpJyQ8lf","executionInfo":{"status":"ok","timestamp":1692439757478,"user_tz":-120,"elapsed":345,"user":{"displayName":"Ha Do Thu","userId":"03677637701219815341"}},"outputId":"9c70379d-2e14-47ad-e413-b5b8ebcfe475"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['readings', 'idx_anomaly', 'training', 'test', 'train_m', 'train_std', 'idx_anomaly_test']\n"]}]},{"cell_type":"code","source":["# Using Transformer-Fourier\n","\n","testing_config_path = '/content/drive/MyDrive/PhDResearch/ATRAF/Anomaly-Detection-with-Transformer-Encoder/result'\n","\n","dataset = CustomDataset(config, train=False)\n","data_loader = create_dataloader(dataset, config)\n","encoder, trans_model = load_model(config)\n","mask = create_mask(config)\n","loss = torch.nn.MSELoss()\n","n_test = len(dataset)\n","recon_loss = np.zeros(n_test)\n","\n","start = time.time()\n","for i, batch in enumerate(data_loader):\n","    src = encoder(batch[\"input\"].float())\n","    trg = encoder(batch[\"target\"].float())\n","    out = trans_model(src, src_mask=mask)\n","    for j in range(config[\"batch_size\"]):\n","        try:\n","            recon_loss[i * config[\"batch_size\"] + j] = loss(\n","                out[j, config[\"pre_mask\"]:config[\"post_mask\"], :], trg[j, config[\"pre_mask\"]:config[\"post_mask\"], :])\n","        except:\n","            pass\n","\n","idx_anomaly_test = dataset.data[\"idx_anomaly_test\"]\n","anomaly_index, test_labels = create_labels(idx_anomaly_test,\n","                                            n_test,\n","                                            config)\n","\n","# Now select a threshold\n","threshold, auc = select_threshold(recon_loss,\n","                                  anomaly_index,\n","                                  test_labels,\n","                                  config)\n","config[\"AUC\"] = auc\n","\n","KQp_thres, q_best = select_KQp_threshold(threshold, recon_loss)\n","config[\"q_best\"] = q_best\n","idx_detection = return_anomaly_idx_by_threshold(recon_loss, KQp_thres)\n","# print(idx_detection)\n","idx_detection_augmented = augment_detected_idx(idx_detection, anomaly_index)\n","# print(anomaly_index_lstm)\n","# print(idx_detection_augmented)\n","precision, recall, F1, _, n_TP, n_FP, n_FN = compute_precision_and_recall(idx_detection_augmented,\n","                                                                          test_labels)\n","config[\"precision\"] = precision\n","config[\"recall\"] = recall\n","config[\"F1\"] = F1\n","config[\"inference_time\"] = (time.time() - start) / 60\n","save_config(config)\n","print(\"\\nPR evaluation using KQE:\")\n","print(\"Precision: {}\".format(precision))\n","print(\"Recall: {}\".format(recall))\n","print(\"F1: {}\".format(F1))\n","print(\"TP: {}\".format(n_TP))\n","print(\"FP: {}\".format(n_FP))\n","print(\"FN: {}\".format(n_FN))"],"metadata":{"id":"Jnuau8Y1FHRm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZXLAF3wCMuBh"},"execution_count":null,"outputs":[]}]}